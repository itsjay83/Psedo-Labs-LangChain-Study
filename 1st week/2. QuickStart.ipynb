{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuickStart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (0.1.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.28 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (0.0.28)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (0.1.32)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (0.1.31)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (4.3.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (0.0.8)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.27 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-openai) (0.1.32)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-openai) (1.14.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (0.1.31)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain-openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.27->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.27->langchain-openai) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-openai) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/itsjay.83/Documents/LangChain_QuickStart/env/lib/python3.11/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain-openai) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# LLM Chain\n",
    "%pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_openai 패키지에서 ChatOpenAI 클래스를 가져옴\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 클래스의 인스턴스를 생성\n",
    "# 이 인스턴스를 사용하여 OpenAI의 대화형 AI 기능을 사용할 수 있다.\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"how can langsmith help with testing?\"이라는 질문을 \n",
    "# ChatOpenAI 인스턴스를 통해 언어 모델에 전송.\n",
    "# 이 메소드는 언어 모델의 응답을 반환.\n",
    "response = llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_core 모듈의 prompts 서브모듈에서 ChatPromptTemplate 클래스를 가져옴.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ChatPromptTemplate 클래스의 from_messages 클래스 메소드를 사용하여 새 프롬프트 템플릿을 생성.\n",
    "# 이 템플릿은 대화 형식으로 되어 있으며, 'system'과 'user'라는 두 가지 역할의 메시지를 포함.\n",
    "# 'system' 역할의 메시지는 \"You are world class technical documentation writer.\"이며,\n",
    "# 'user' 역할의 메시지는 사용자 입력('{input}')을 표시하는 자리 표시자로 설정됨.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 객체와 llm 객체를 파이프 연산자를 사용하여 연결한다.\n",
    "# 이 연결을 통해 prompt에서 정의된 템플릿을 사용하여 질문이나 명령을 구성하고,\n",
    "# 이를 llm 객체를 통해 처리하여 AI의 응답을 받을 수 있다.\n",
    "# 결과적으로, 이 연결(chain)은 사용자의 입력을 받아 AI의 응답을 생성하는 흐름을 정의한다.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing in various ways:\\n\\n1. Automated Testing: Langsmith can be used to generate test cases, test data, and test scripts automatically, which can facilitate automated testing of software applications. This can help in improving testing efficiency and coverage.\\n\\n2. Test Coverage: Langsmith can be used to analyze the codebase and identify areas that are not covered by existing test cases. This can help in improving test coverage and ensuring that all parts of the code are adequately tested.\\n\\n3. Test Data Generation: Langsmith can generate realistic and diverse test data, which can be used to validate the behavior of the software under different scenarios. This can help in uncovering bugs and edge cases that may not be apparent with limited test data.\\n\\n4. Performance Testing: Langsmith can be used to simulate large user loads and stress test the software application. This can help in identifying performance bottlenecks and ensuring that the software can handle the expected user traffic.\\n\\n5. Security Testing: Langsmith can be used to generate security test cases and simulate various security attacks on the software application. This can help in identifying vulnerabilities and ensuring that the software is secure against potential threats.\\n\\nOverall, Langsmith can be a valuable tool for testing teams to improve the quality and reliability of software applications.', response_metadata={'token_usage': {'completion_tokens': 256, 'prompt_tokens': 27, 'total_tokens': 283}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메소드를 사용하여 \"how can langsmith help with testing?\"이라는 질문을 처리.\n",
    "# 이때, 입력은 {\"input\": \"how can langsmith help with testing?\"}의 형태로 딕셔너리에 담겨 있다.\n",
    "# chain은 prompt와 llm 객체를 연결하여, prompt를 통해 질문을 구성하고 llm을 통해 AI의 응답을 생성한다.\n",
    "# AI로부터의 응답은 이 메소드를 호출한 곳으로 반환된다.\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_core 라이브러리의 output_parsers 모듈에서 StrOutputParser 클래스를 가져온다.\n",
    "# 이 클래스는 언어 모델의 출력을 문자열로 파싱하는 기능을 제공한다.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# StrOutputParser 클래스의 인스턴스를 생성한다.\n",
    "# 생성된 인스턴스는 언어 모델의 출력을 문자열로 변환하는데 사용될 수 있다.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt, llm, output_parser 객체를 순차적으로 연결한다.\n",
    "# 이 연결(chain)은 다음 과정을 포함한다.:\n",
    "# 1. prompt: 사용자의 입력을 포함한 프롬프트를 생성한다.\n",
    "# 2. llm: 생성된 프롬프트를 기반으로 AI(예: OpenAI)에 질문을 하고 응답을 받는다.\n",
    "# 3. output_parser: AI의 응답을 문자열로 파싱하여 처리 가능한 형태로 변환한다.\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langsmith can help with testing in several ways:\\n\\n1. Test Automation: Langsmith can be used to automate testing tasks, such as creating test scripts, running tests, and analyzing test results. This can help reduce the time and effort required for testing, improve test coverage, and ensure more consistent and reliable testing.\\n\\n2. Test Data Generation: Langsmith can be used to generate test data automatically, helping to create a wide range of test scenarios and cover different data input combinations. This can improve the effectiveness of testing and help uncover potential issues or bugs in the software.\\n\\n3. Performance Testing: Langsmith can be used to simulate large numbers of users or transactions to test the performance and scalability of a system. This can help identify performance bottlenecks and optimize the system for better performance.\\n\\n4. Regression Testing: Langsmith can be used to automate regression testing, helping to quickly re-run tests after code changes to ensure that new updates haven't introduced any new bugs or issues. This can help maintain the quality and stability of the software over time.\\n\\n5. Integration Testing: Langsmith can be used to automate integration testing, where different components or systems are tested together to ensure they work correctly when integrated. This can help identify issues with interactions between different parts of the software and ensure that the system as a whole functions as expected.\\n\\nOverall, Langsmith can help streamline and improve the testing process, making it more efficient, effective, and reliable.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메소드를 사용하여 \"how can langsmith help with testing?\"이라는 질문을 처리한다.\n",
    "# 여기서 chain은 prompt (프롬프트 생성), llm (언어 모델을 통한 응답 생성), 그리고 output_parser (응답 파싱)를 포함한다.\n",
    "# 1. prompt는 사용자 입력을 받아 프롬프트를 형성한다.\n",
    "# 2. 이 형성된 프롬프트는 llm을 통해 언어 모델에 전달되어, 질문에 대한 응답을 생성한다.\n",
    "# 3. 생성된 응답은 output_parser를 통해 최종적으로 문자열로 파싱되어, 사용자가 이해하기 쉬운 형태로 반환된다.\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 우리는 기본적인 LLM 체인을 성공적으로 설정했습니다. 하지만 우리는 프롬프트, 모델, 출력 파서의 기본 사항에 대해서만 언급했기 때문에 여러 섹션에 걸처 세부적인 내용을 확인하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Chain\n",
    "\n",
    "원래 질문(\"langsmith가 테스트에 어떻게 도움이 될 수 있는가?\")에 제대로 답하기 위해서, 우리는 LLM에게 추가적인 문맥을 제공할 필요가 있습니다. \n",
    "이를 위해 검색을 통한 정보 제공을 사용할 수 있고, 이는 LLM에게 직접 전달하기에는 너무 많은 데이터가 있을 때 검색이 유용합니다.\n",
    "그럴 때에는 검색기를 사용하여 가장 관련성 높은 자료들만을 가져와서 그것들을 전달할 수 있습니다.\n",
    "\n",
    "이 과정에서, 우리는 검색기로부터 관련 문서를 찾아내고 그것들을 프롬프트에 전달할 것 입니다.\n",
    "검색기는 SQL 테이블, 인터넷 등 무엇이든 될 수 있지만, 이 경우에는 벡터 저장소를 채우고 그것을 검색기로 사용할 것입니다.\n",
    "벡터 저장소에 대한 더 자세한 정보는 [이 문서](https://python.langchain.com/docs/modules/data_connection/vectorstores)를 참조하십쇼."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 먼저, 인덱싱하고자 하는 데이터를 로드해야 합니다. 이를 위해 WebBaseLoader를 사용할 것입니다. 이는 BeautifulSoup를 설치하는 것을 요구합니다:\n",
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로, 벡터스토어(vectorstore)에 인덱싱해야 합니다. 이 작업에는 몇 가지 구성 요소, 즉 임베딩 모델과 벡터스토어가 필요합니다.\n",
    "임베딩 모델의 경우, API를 통해 접근하거나 로컬 모델을 실행하는 예시를 다시 제공합니다.\n",
    "\n",
    "\n",
    "langchain_openai 패키지가 설치되어 있고 적절한 환경 변수가 설정되어 있는지 확인하세요(OPENAI_API_KEY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_openai에서 OpenAIEmbeddings를 가져옵니다.\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# embeddings 인스턴스를 생성합니다.\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 임베딩 모델을 사용하여 문서를 벡터스토어에 입력할 수 있습니다. 간단함을 위해 로컬 벡터스토어인 FAISS를 사용할 것입니다.\n",
    "\n",
    "먼저 필요한 패키지를 설치해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/jaylee_83/Documents/_itsjayspace/_myStudys/Psedo-Labs-LangChain-Study/env/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Downloading faiss_cpu-1.8.0-cp312-cp312-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS 및 RecursiveCharacterTextSplitter를 가져옵니다.\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 텍스트 스플리터 인스턴스를 생성합니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "# 문서를 분할합니다.\n",
    "documents = text_splitter.split_documents(docs)\n",
    "# 문서에서 벡터를 생성합니다.\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 데이터를 벡터스토어에 인덱싱했으므로, 검색 체인을 생성할 것입니다. 이 체인은 들어오는 질문을 받아 관련 문서를 찾고, 이 문서들을 원본 질문과 함께 LLM에 전달하여 원본 질문에 대한 답변을 요청합니다.\n",
    "\n",
    "먼저 질문과 검색된 문서를 받아 답변을 생성하는 체인을 설정합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 결합 체인을 생성합니다.\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# 프롬프트 템플릿을 설정합니다.\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "# 문서 체인을 생성합니다.\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help with testing by allowing you to visualize test results.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원한다면, 문서를 직접 전달하여 이를 실행할 수 있습니다.\n",
    "# Document를 가져옵니다.\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 문서 체인을 호출합니다.\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, 우리는 문서가 먼저 방금 설정한 검색기에서 나오기를 원합니다. \n",
    "\n",
    "이렇게 하면 주어진 질문에 대해 검색기를 사용하여 가장 관련성 높은 문서를 동적으로 선택하고 이를 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 체인을 생성합니다.\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "# 검색기를 설정합니다.\n",
    "retriever = vector.as_retriever()\n",
    "# 검색 체인을 생성합니다.\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith can help with testing by allowing developers to create datasets, run tests on LLM applications, upload test cases in bulk or create them on the fly, run custom evaluations, compare different versions of applications, provide a playground environment for rapid iteration and experimentation, collect data during beta testing, capture feedback from users, annotate traces, add runs to datasets, and monitor key metrics over time.\n"
     ]
    }
   ],
   "source": [
    "# 검색 체인을 호출합니다.\n",
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "# 답변을 출력합니다.\n",
    "print(response[\"answer\"])\n",
    "# LangSmith는 여러 기능을 제공하여 테스트에 도움을 줄 수 있습니다:..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Retrieval Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 만든 체인은 단일 질문에만 답변할 수 있습니다. 사람들이 만들고 있는 LLM 응용 프로그램의 주요 유형 중 하나는 챗봇입니다. 그렇다면 이 체인을 어떻게 따라오는 질문에 답변할 수 있는 체인으로 전환할 수 있을까요?\n",
    "\n",
    "`create_retrieval_chain` 함수를 여전히 사용할 수 있지만, 두 가지를 변경해야 합니다:\n",
    "\n",
    "1. 검색 방법은 이제 가장 최근 입력에만 작동하는 것이 아니라 전체 기록을 고려해야 합니다.\n",
    "\n",
    "2. 최종 LLM 체인 또한 전체 기록을 고려해야 합니다\n",
    "\n",
    "### 검색 업데이트\n",
    "\n",
    "검색을 업데이트하기 위해 새 체인을 생성할 것입니다. 이 체인은 가장 최근의 입력(`input`)과 대화 기록(`chat_history`)을 받아 LLM을 사용하여 검색 쿼리를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# 검색 쿼리를 생성하기 위해 LLM에 전달할 수 있는 프롬프트가 필요합니다.\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자가 후속 질문을 하는 인스턴스를 전달하여 이를 테스트해 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content='LangSmith User Guide | 🦜️🛠️ LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content=\"This allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.\\nEvery playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production. However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Was this page helpful?PreviousLangSmithNextSetupPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것은 LLM이 새로운 쿼리를 생성하여 대화 기록과 후속 질문을 결합했기 때문에 LangSmith에서 테스팅에 관한 문서를 반환합니다.\n",
    "\n",
    "이제 이 새로운 검색기가 있으므로, 검색된 문서를 염두에 두고 대화를 계속할 수 있는 새로운 체인을 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 처음부터 끝까지 테스트해 볼 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'context': [Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyCookbookUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='LangSmith User Guide | 🦜️🛠️ LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content=\"This allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.\\nEvery playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production. However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Was this page helpful?PreviousLangSmithNextSetupPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})],\n",
       " 'answer': 'LangSmith can help test your LLM applications in several ways:\\n\\n1. **Prototyping:** LangSmith allows for quick experimentation between prompts, model types, retrieval strategies, and other parameters to help you prototype your LLM applications effectively.\\n\\n2. **Debugging:** By enabling LangSmith tracing, you can easily debug your applications when issues arise. LangSmith provides clear visibility and debugging information at each step of an LLM sequence, making it easier to identify and resolve issues.\\n\\n3. **Initial Test Set:** You can create datasets of inputs and reference outputs to run tests on your LLM applications. LangSmith makes it easy to run custom evaluations to score test results and ensure your application is performing as expected.\\n\\n4. **Comparison View:** LangSmith offers a user-friendly comparison view for test runs, allowing you to track and diagnose regressions in test scores across different versions of your application.\\n\\n5. **Playground:** LangSmith provides a playground environment for rapid iteration and experimentation, allowing you to test out different prompts and models quickly.\\n\\n6. **Beta Testing:** During beta testing, LangSmith helps you collect data on how your LLM applications are performing in real-world scenarios. You can gather feedback, annotate traces, and add runs to datasets to track improvements and regressions.\\n\\n7. **Monitoring and A/B Testing:** LangSmith provides monitoring charts to track key metrics over time and allows for A/B testing changes in prompt, model, or retrieval strategy. This helps you ensure your application is delivering desirable results at scale.\\n\\nBy utilizing these features and workflows, LangSmith can effectively help you test and improve your LLM applications throughout the development lifecycle.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 하면 일관된 답변을 얻을 수 있습니다 - 우리는 검색 체인을 챗봇으로 성공적으로 전환했습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 우리는 각 단계가 사전에 알려진 체인의 예시를 만들었습니다. 마지막으로 만들 것은 LLM이 어떤 단계를 밟을지 결정하는 에이전트입니다.\n",
    "\n",
    "참고: 이 예제에서는 로컬 모델이 아직 충분히 신뢰할 수 없기 때문에 OpenAI 모델을 사용하여 에이전트를 생성하는 방법만 보여줍니다.\n",
    "\n",
    "에이전트를 구축할 때 처음 해야 할 일 중 하나는 어떤 도구에 접근할 수 있게 할지 결정하는 것입니다. 이 예제에서는 에이전트에 두 가지 도구에 대한 접근 권한을 부여할 것입니다:\n",
    "\n",
    "1. 방금 생성한 검색기. 이를 통해 LangSmith에 대한 질문에 쉽게 답변할 수 있습니다.\n",
    "2. 검색 도구. 이를 통해 최신 정보가 필요한 질문에 쉽게 답변할 수 있습니다.\n",
    "\n",
    "먼저 방금 생성한 검색기에 대한 도구를 설정합시다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기 도구를 생성합니다.\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 사용할 검색 도구는 Tavily입니다. 이것은 API 키가 필요하며(넉넉한 무료 계층을 제공), 해당 플랫폼에서 생성한 후 환경 변수로 설정해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export TAVILY_API_KEY=...\n",
    "\n",
    "# Tavily 검색 결과 도구를 생성합니다.\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 우리가 작업하고 싶은 도구의 목록을 생성할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "도구를 갖추었으니, 이를 사용할 에이전트를 생성할 수 있습니다. 이 부분은 빠르게 넘어갈 것입니다 - 정확히 무슨 일이 일어나고 있는지 더 깊이 파고들고 싶다면 에이전트의 시작 문서를 확인하세요.\n",
    "\n",
    "먼저 langchain hub를 설치하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchainhub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 미리 정의된 프롬프트를 가져올 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트와 관련된 모듈을 가져옵니다.\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# 사용할 프롬프트를 가져옵니다 - 이를 수정할 수 있습니다!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 에이전트를 호출하고 어떻게 반응하는지 볼 수 있습니다! LangSmith에 대한 질문을 할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "날씨에 대해 물어볼 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"what is the weather in SF?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 대화를 나눌 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "agent_executor.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving with LangServe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 애플리케이션을 구축했으니, 이를 서비스할 차례입니다. 바로 여기서 LangServe가 등장합니다. LangServe는 개발자들이 LangChain 체인을 REST API로 배포할 수 있도록 도와줍니다. LangChain을 사용하기 위해 꼭 LangServe를 사용할 필요는 없지만, 이 가이드에서는 LangServe를 이용해 앱을 배포하는 방법을 소개하겠습니다.\n",
    "\n",
    "이 가이드의 첫 번째 부분은 주피터 노트북에서 실행될 예정이었지만, 이제 그 환경을 벗어나 Python 파일을 생성하고 커맨드 라인을 통해 이와 상호작용하게 됩니다.\n",
    "\n",
    "설치는 다음과 같이 진행합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"langserve[all]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서버 생성\n",
    "애플리케이션을 위한 서버를 만들기 위해서는 serve.py 파일을 만들어야 합니다. 이 파일에는 애플리케이션을 서비스하기 위한 로직이 포함됩니다. 크게 세 가지로 구성됩니다:\n",
    "\n",
    "1. 위에서 구축한 체인의 정의\n",
    "2. FastAPI 앱\n",
    "3. `langserve.add_routes`를 사용하여 체인을 제공할 경로의 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from typing import List\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from langchain_core.prompts import ChatPromptTemplate  # 채팅 프롬프트 템플릿\n",
    "from langchain_openai import ChatOpenAI  # 채팅 OpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader  # 문서 로더\n",
    "from langchain_openai import OpenAIEmbeddings  # OpenAI 임베딩\n",
    "from langchain_community.vectorstores import FAISS  # FAISS 벡터 저장소\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter  # 재귀적 문자 텍스트 분할기\n",
    "from langchain.tools.retriever import create_retriever_tool  # 검색 도구 생성 함수\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults  # Tavily 검색 결과\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent  # OpenAI 기능 에이전트 생성 함수\n",
    "from langchain.agents import AgentExecutor  # 에이전트 실행자\n",
    "from langchain.pydantic_v1 import BaseModel, Field  # 기본 모델 및 필드\n",
    "from langchain_core.messages import BaseMessage  # 기본 메시지\n",
    "from langserve import add_routes  # 경로 추가\n",
    "\n",
    "# 1. 검색 도구 로드\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# 2. 도구 생성\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"LangSmith에 대한 정보 검색. LangSmith에 관한 모든 질문은 이 도구를 사용해야 합니다!\",\n",
    ")\n",
    "search = TavilySearchResults()\n",
    "tools = [retriever_tool, search]\n",
    "\n",
    "# 3. 에이전트 생성\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# 4. 앱 정의\n",
    "app = FastAPI(\n",
    "  title=\"LangChain Server\",\n",
    "  version=\"1.0\",\n",
    "  description=\"LangChain의 Runnable 인터페이스를 사용하는 간단한 API 서버\",\n",
    ")\n",
    "\n",
    "# 5. 체인 경로 추가\n",
    "\n",
    "# 현재 AgentExecutor에 스키마가 부족하기 때문에, 이 입력/출력 스키마를 추가해야 합니다.\n",
    "\n",
    "class Input(BaseModel):\n",
    "    input: str\n",
    "    chat_history: List[BaseMessage] = Field(\n",
    "        ...,\n",
    "        extra={\"widget\": {\"type\": \"chat\", \"input\": \"location\"}},\n",
    "    )\n",
    "\n",
    "class Output(BaseModel):\n",
    "    output: str\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    agent_executor.with_types(input_type=Input, output_type=Output),\n",
    "    path=\"/agent\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 하면, 파일을 실행했을 때:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python serve.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "localhost:8000에서 체인이 제공되는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PlayGraound (플레이그라운드)\n",
    "모든 LangServe 서비스에는 스트리밍 출력과 중간 단계의 가시성을 갖춘 애플리케이션을 구성하고 호출할 수 있는 간단한 내장 UI가 제공됩니다. http://localhost:8000/agent/playground/로 이동하여 직접 시도해 보세요! 이전과 같은 질문인 \"how can langsmith help with testing?\"을 입력하면 이전과 동일하게 응답해야 합니다.\n",
    "\n",
    "### Client (클라이언트)\n",
    "이제 우리 서비스와 프로그래밍 방식으로 상호 작용하기 위한 클라이언트를 설정해 보겠습니다. 이 작업은 langserve.RemoteRunnable을 사용하여 쉽게 수행할 수 있습니다. 이를 통해, 마치 클라이언트 측에서 실행되는 것처럼 제공된 체인과 상호 작용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "remote_chain = RemoteRunnable(\"http://localhost:8000/agent/\")\n",
    "remote_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"chat_history\": []  # 첫 번째 호출이므로 빈 리스트를 제공\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Chain\n",
    "%pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_openai 패키지에서 ChatOpenAI 클래스를 가져옴\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 클래스의 인스턴스를 생성\n",
    "# 이 인스턴스를 사용하여 OpenAI의 대화형 AI 기능을 사용할 수 있다.\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing by providing automated testing tools that can quickly and accurately test software applications for bugs, errors, and performance issues. It can also help with test case management, test script creation, and test execution, making the testing process more efficient and effective. Additionally, Langsmith can help with test data generation, test coverage analysis, and test result reporting, ensuring that all aspects of the testing process are covered and documented.', response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 15, 'total_tokens': 102}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"how can langsmith help with testing?\"이라는 질문을 \n",
    "# ChatOpenAI 인스턴스를 통해 언어 모델에 전송.\n",
    "# 이 메소드는 언어 모델의 응답을 반환.\n",
    "response = llm.invoke(\"how can langsmith help with testing?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_core 모듈의 prompts 서브모듈에서 ChatPromptTemplate 클래스를 가져옴.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ChatPromptTemplate 클래스의 from_messages 클래스 메소드를 사용하여 새 프롬프트 템플릿을 생성.\n",
    "# 이 템플릿은 대화 형식으로 되어 있으며, 'system'과 'user'라는 두 가지 역할의 메시지를 포함.\n",
    "# 'system' 역할의 메시지는 \"You are world class technical documentation writer.\"이며,\n",
    "# 'user' 역할의 메시지는 사용자 입력('{input}')을 표시하는 자리 표시자로 설정됨.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 객체와 llm 객체를 파이프 연산자를 사용하여 연결한다.\n",
    "# 이 연결을 통해 prompt에서 정의된 템플릿을 사용하여 질문이나 명령을 구성하고,\n",
    "# 이를 llm 객체를 통해 처리하여 AI의 응답을 받을 수 있다.\n",
    "# 결과적으로, 이 연결(chain)은 사용자의 입력을 받아 AI의 응답을 생성하는 흐름을 정의한다.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing in several ways:\\n\\n1. **Automated Testing**: Langsmith can be used to generate test scripts or test data automatically, helping to speed up the testing process and ensure comprehensive test coverage.\\n\\n2. **Test Case Generation**: Langsmith can generate test cases based on the specifications or requirements of the software, making it easier to create test scenarios and ensure all possible scenarios are covered.\\n\\n3. **Test Data Generation**: Langsmith can generate synthetic test data that can be used to test the software under various conditions, helping to identify potential issues and vulnerabilities.\\n\\n4. **Regression Testing**: Langsmith can be used to automate the process of regression testing, ensuring that new code changes do not introduce any unexpected issues or bugs in the software.\\n\\n5. **Performance Testing**: Langsmith can be used to generate test scenarios for performance testing, helping to simulate real-world usage conditions and identify performance bottlenecks in the software.\\n\\nOverall, Langsmith can help streamline the testing process, improve test coverage, and ensure the quality and reliability of the software being tested.', response_metadata={'token_usage': {'completion_tokens': 215, 'prompt_tokens': 27, 'total_tokens': 242}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메소드를 사용하여 \"how can langsmith help with testing?\"이라는 질문을 처리.\n",
    "# 이때, 입력은 {\"input\": \"how can langsmith help with testing?\"}의 형태로 딕셔너리에 담겨 있다.\n",
    "# chain은 prompt와 llm 객체를 연결하여, prompt를 통해 질문을 구성하고 llm을 통해 AI의 응답을 생성한다.\n",
    "# AI로부터의 응답은 이 메소드를 호출한 곳으로 반환된다.\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_core 라이브러리의 output_parsers 모듈에서 StrOutputParser 클래스를 가져온다.\n",
    "# 이 클래스는 언어 모델의 출력을 문자열로 파싱하는 기능을 제공한다.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# StrOutputParser 클래스의 인스턴스를 생성한다.\n",
    "# 생성된 인스턴스는 언어 모델의 출력을 문자열로 변환하는데 사용될 수 있다.\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt, llm, output_parser 객체를 순차적으로 연결한다.\n",
    "# 이 연결(chain)은 다음 과정을 포함한다.:\n",
    "# 1. prompt: 사용자의 입력을 포함한 프롬프트를 생성한다.\n",
    "# 2. llm: 생성된 프롬프트를 기반으로 AI(예: OpenAI)에 질문을 하고 응답을 받는다.\n",
    "# 3. output_parser: AI의 응답을 문자열로 파싱하여 처리 가능한 형태로 변환한다.\n",
    "chain = prompt | llm | output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 객체의 invoke 메소드를 사용하여 \"how can langsmith help with testing?\"이라는 질문을 처리한다.\n",
    "# 여기서 chain은 prompt (프롬프트 생성), llm (언어 모델을 통한 응답 생성), 그리고 output_parser (응답 파싱)를 포함한다.\n",
    "# 1. prompt는 사용자 입력을 받아 프롬프트를 형성한다.\n",
    "# 2. 이 형성된 프롬프트는 llm을 통해 언어 모델에 전달되어, 질문에 대한 응답을 생성한다.\n",
    "# 3. 생성된 응답은 output_parser를 통해 최종적으로 문자열로 파싱되어, 사용자가 이해하기 쉬운 형태로 반환된다.\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 우리는 기본적인 LLM 체인을 성공적으로 설정했습니다. 하지만 우리는 프롬프트, 모델, 출력 파서의 기본 사항에 대해서만 언급했기 때문에 여러 섹션에 걸처 세부적인 내용을 확인하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
